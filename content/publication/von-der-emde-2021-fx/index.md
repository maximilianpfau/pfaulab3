---
title: AI-based structure-function correlation in age-related macular degeneration
authors:
- Leon von der Emde
- Maximilian Pfau
- Frank G Holz
- Monika Fleckenstein
- Karsten Kortuem
- Pearse A Keane
- Daniel L Rubin
- Steffen Schmitz-Valckenberg
date: '2021-08-01'
publishDate: '2025-10-25T11:28:52.578210Z'
publication_types:
- article-journal
publication: '*EYE*'
abstract: Sensitive and robust outcome measures of retinal function are pivotal for
  clinical trials in age-related macular degeneration (AMD). A recent development
  is the implementation of artificial intelligence (AI) to infer results of psychophysical
  examinations based on findings derived from multimodal imaging. We conducted a review
  of the current literature referenced in PubMed and Web of Science among others with
  the keywords 'artificial intelligence' and 'machine learning' in combination with
  'perimetry', 'best-corrected visual acuity (BCVA)', 'retinal function' and 'age-related
  macular degeneration'. So far AI-based structure-function correlations have been
  applied to infer conventional visual field, fundus-controlled perimetry, and electroretinography
  data, as well as BCVA, and patient-reported outcome measures (PROM). In neovascular
  AMD, inference of BCVA (hereafter termed inferred BCVA) can estimate BCVA results
  with a root mean squared error of ~7-11 letters, which is comparable to the accuracy
  of actual visual acuity assessment. Further, AI-based structure-function correlation
  can successfully infer fundus-controlled perimetry (FCP) results both for mesopic
  as well as dark-adapted (DA) cyan and red testing (hereafter termed inferred sensitivity).
  Accuracy of inferred sensitivity can be augmented by adding short FCP examinations
  and reach mean absolute errors (MAE) of ~3-5 dB for mesopic, DA cyan and DA red
  testing. Inferred BCVA, and inferred retinal sensitivity, based on multimodal imaging,
  may be considered as a quasi-functional surrogate endpoint for future interventional
  clinical trials in the future.
---
